{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Title\n",
    "\n",
    "This notebook lists all the steps that you need to complete the complete this project. You will need to complete all the TODOs in this notebook as well as in the README and the two python scripts included with the starter code.\n",
    "\n",
    "\n",
    "**TODO**: Give a helpful introduction to what this notebook is for. Remember that comments, explanations and good documentation make your project informative and professional.\n",
    "\n",
    "**Note:** This notebook has a bunch of code and markdown cells with TODOs that you have to complete. These are meant to be helpful guidelines for you to finish your project while meeting the requirements in the project rubrics. Feel free to change the order of these the TODO's and use more than one TODO code cell to do all your tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Install any packages that you might need\n",
    "# For instance, you will need the smdebug package\n",
    "!pip install smdebug --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# TODO: Import any packages that you might need\n",
    "# For instance you will need Boto3 and Sagemaker\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# AWS\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "# Data\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUCKET='sagemaker-us-east-1-934421875319'\n",
      "REGION='us-east-1'\n",
      "ROLE='arn:aws:iam::934421875319:role/service-role/AmazonSageMaker-ExecutionRole-20250109T052241'\n"
     ]
    }
   ],
   "source": [
    "SESSION = sagemaker.Session()\n",
    "\n",
    "BUCKET= SESSION.default_bucket()\n",
    "REGION = SESSION.boto_region_name\n",
    "ROLE = sagemaker.get_execution_role()\n",
    "\n",
    "print(f\"{BUCKET=}\")\n",
    "print(f\"{REGION=}\")\n",
    "print(f\"{ROLE=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "TODO: Explain what dataset you are using for this project. Maybe even give a small overview of the classes, class distributions etc that can help anyone not familiar with the dataset get a better understand of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Fetch and upload the data to AWS S3\n",
    "\n",
    "# Command to download and unzip data\n",
    "# !wget --no-check-certificate  https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
    "# !unzip -qq dogImages.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>class_number</th>\n",
       "      <th>class_name</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>dogImages/test/001.Affenpinscher/Affenpinscher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>dogImages/test/001.Affenpinscher/Affenpinscher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>dogImages/test/001.Affenpinscher/Affenpinscher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>dogImages/test/001.Affenpinscher/Affenpinscher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>dogImages/test/001.Affenpinscher/Affenpinscher...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset_type  class_number     class_name  \\\n",
       "0         test             1  Affenpinscher   \n",
       "1         test             1  Affenpinscher   \n",
       "2         test             1  Affenpinscher   \n",
       "3         test             1  Affenpinscher   \n",
       "4         test             1  Affenpinscher   \n",
       "\n",
       "                                           file_path  \n",
       "0  dogImages/test/001.Affenpinscher/Affenpinscher...  \n",
       "1  dogImages/test/001.Affenpinscher/Affenpinscher...  \n",
       "2  dogImages/test/001.Affenpinscher/Affenpinscher...  \n",
       "3  dogImages/test/001.Affenpinscher/Affenpinscher...  \n",
       "4  dogImages/test/001.Affenpinscher/Affenpinscher...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def create_dataframe(dataset_path):\n",
    "    data = []\n",
    "\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        path_parts = root.split(os.sep)\n",
    "        \n",
    "        if len(path_parts) >= 3 and path_parts[-2] in ['test', 'train', 'valid']:\n",
    "            dataset_type = path_parts[-2]\n",
    "            class_info = path_parts[-1].split('.')\n",
    "            \n",
    "            if len(class_info) == 2:\n",
    "                class_number = int(class_info[0])\n",
    "                class_name = class_info[1]\n",
    "                \n",
    "                for file in files:\n",
    "                    if file.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                        file_path = os.path.join(root, file)\n",
    "                        data.append([dataset_type,class_number, class_name, file_path])\n",
    "    \n",
    "\n",
    "    df = pd.DataFrame(data, columns=['dataset_type','class_number', 'class_name', 'file_path'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "dog_df = create_dataframe('dogImages')\n",
    "dog_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classes: 133\n",
      "Total images: 8351\n",
      "Images per dataset:\n",
      "dataset_type\n",
      "test      836\n",
      "train    6680\n",
      "valid     835\n",
      "Name: class_number, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Total classes: {dog_df.class_number.nunique()}')\n",
    "print(f'Total images: {len(dog_df)}')\n",
    "print(f'Images per dataset:\\n{dog_df.groupby([\"dataset_type\"]).class_number.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_grid(df, n_images=9):\n",
    "    # Randomly sample n_images from the dataframe\n",
    "    sample_df = df.sample(n=n_images)\n",
    "    \n",
    "    # Create a figure with 3x3 subplots\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Get the image file path and class name\n",
    "        img_path = sample_df.iloc[i]['file_path']\n",
    "        class_name = sample_df.iloc[i]['class_name']\n",
    "        \n",
    "        # Read and plot the image\n",
    "        img = mpimg.imread(img_path)\n",
    "        ax.imshow(img)\n",
    "        \n",
    "        # Set the title as the class name\n",
    "        ax.set_title(class_name, fontsize=12)\n",
    "        \n",
    "        # Remove the axis ticks\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_image_grid(dog_df, n_images=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dog_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/Udacity_ML_AWS/project_3/train_and_deploy.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://te2z2gutofgn7lv.studio.us-east-1.sagemaker.aws/home/sagemaker-user/Udacity_ML_AWS/project_3/train_and_deploy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m dog_df\u001b[39m.\u001b[39mfile_path\u001b[39m.\u001b[39mvalues()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dog_df' is not defined"
     ]
    }
   ],
   "source": [
    "dog_df.file_path.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    try:\n",
    "        s3.upload_file(local_path, bucket, s3_key)\n",
    "        print(f\"Uploaded {local_path} to s3://{bucket}/{s3_key}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading {local_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "**TODO:** This is the part where you will finetune a pretrained model with hyperparameter tuning. Remember that you have to tune a minimum of two hyperparameters. However you are encouraged to tune more. You are also encouraged to explain why you chose to tune those particular hyperparameters and the ranges.\n",
    "\n",
    "**Note:** You will need to use the `hpo.py` script to perform hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Declare your HP ranges, metrics etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create estimators for your HPs\n",
    "\n",
    "estimator = # TODO: Your estimator here\n",
    "\n",
    "tuner = # TODO: Your HP tuner here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit your HP Tuner\n",
    "tuner.fit() # TODO: Remember to include your data channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get the best estimators and the best HPs\n",
    "\n",
    "best_estimator = #TODO\n",
    "\n",
    "#Get the hyperparameters of the best trained model\n",
    "best_estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Profiling and Debugging\n",
    "TODO: Using the best hyperparameters, create and finetune a new model\n",
    "\n",
    "**Note:** You will need to use the `train_model.py` script to perform model profiling and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set up debugging and profiling rules and hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create and fit an estimator\n",
    "\n",
    "estimator = # TODO: Your estimator here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot a debugging output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Is there some anomalous behaviour in your debugging output? If so, what is the error and how will you fix it?  \n",
    "**TODO**: If not, suppose there was an error. What would that error look like and how would you have fixed it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display the profiler output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deploying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Deploy your model to an endpoint\n",
    "\n",
    "predictor=estimator.deploy() # TODO: Add your deployment configuration like instance type and number of instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run an prediction on the endpoint\n",
    "\n",
    "image = # TODO: Your code to load and preprocess image to send to endpoint for prediction\n",
    "response = predictor.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remember to shutdown/delete your endpoint once your work is done\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
